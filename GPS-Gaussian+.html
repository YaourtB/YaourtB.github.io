<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Projectpage of GPS-Gaussian+</title>
    <!-- Bootstrap -->
    <link href="assets/GPS-Gaussian+/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>GPS-Gaussian+: Generalizable Pixel-Wise 3D Gaussian Splatting<br>for Real-Time Human-Scene Rendering from Sparse Views</h2>
            <!--<h4 style="color:#5a6268;">CVPR 2024 Highlight</h4>-->
            <hr>
            <h6> <a href="https://yaourtb.github.io" target="_blank">Boyao Zhou<sup>1</sup>*</a>, 
                <a href="https://shunyuanzheng.github.io" target="_blank">Shunyuan Zheng<sup>2</sup>*<sup>&dagger;</sup></a>,
                <a href="https://itoshiko.com/" target="_blank">Hanzhang Tu<sup>1</sup></a>,
                <a href="https://dsaurus.github.io/saurus" target="_blank">Ruizhi Shao<sup>1</sup></a>,
                <a href="https://liuboning2.github.io" target="_blank">Boning Liu<sup>1</sup></a>,
                <a href="http://homepage.hit.edu.cn/zhangshengping" target="_blank">Shengping Zhang<sup>2&#x2709;</sup></a>,
                <a href="https://liqiangnie.github.io" target="_blank">Liqiang Nie<sup>2</sup></a>,
                <a href="https://liuyebin.com" target="_blank">Yebin Liu<sup>1</sup></a></h6>
            <p><sup>1</sup>Tsinghua University<sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2</sup>Harbin Institute of Technology
            <br>*Equal contribution<sup>&nbsp;&nbsp;&dagger;</sup>Work done during an internship at Tsinghua University&nbsp;&nbsp;<sup>&#x2709</sup>Corresponding author
            </p>

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2411.11363" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/YaourtB/GPS_plus" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code</a></p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://docs.google.com/forms/d/e/1FAIpQLSexKlYfpUFcgnKM7EYoIFWi7P3J1InlHyTC82ehqka2hTiwmA/viewform?usp=dialog" role="button"  target="_blank">
                  <i class="fa fa-database"></i> THuman_MV Data</a></p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://shunyuanzheng.github.io/GPS-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-backward"></i> CVPR Version</a></p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>

          <p class="text-left"> Differentiable rendering techniques have recently shown promising results for free-viewpoint video synthesis of characters. However, such methods, either Gaussian Splatting or neural implicit rendering, typically necessitate per-subject optimization which does not meet the requirement of real-time rendering in an interactive application. We propose a generalizable Gaussian Splatting approach for high-resolution image rendering under a sparse-view camera setting. To this end, we introduce Gaussian parameter maps defined on the source views and directly regress Gaussian properties for instant novel view synthesis without any fine-tuning or optimization. We train our Gaussian parameter regression module on human-only data or human-scene data, jointly with a depth estimation module to lift 2D parameter maps to 3D space. The proposed framework is fully differentiable with both depth and rendering supervision or with only rendering supervision. We further introduce a regularization term and an epipolar attention mechanism to preserve geometry consistency between two source views, especially when neglecting depth supervision. Experiments on several datasets demonstrate that our method outperforms state-of-the-art methods while achieving an exceeding rendering speed. 
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method</h3>
              <hr style="margin-top:0px">
            <img src="assets/GPS-Gaussian+/method_pipeline.png" width="100%" alt=""/>
            <p>&nbsp;</p>
            <p>
              <strong>Overview</strong>: Given RGB images of a human-centered scene with sparse camera views and a target novel viewpoint, we select the adjacent two views on which to formulate our pixel-wise Gaussian representation. We extract the image features by using epipolar attention and then conduct an iterative depth estimation. For each source view, the RGB image serves as a color map, while the other parameters of 3D Gaussians are predicted in a pixel-wise manner. The Gaussian parameter maps defined on 2D image planes of both views are further unprojected to 3D space via refined depth maps and aggregated for novel view rendering. The fully differentiable framework enables a joint training mechanism with only rendering loss and geometry regularization.
            </p>
            <p>&nbsp;</p>
          </div>
      </div>
    </div>
  </section>
  <br>
  
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Live Demo</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Live demo for human-object, multi-person, human-scene interaction scenario</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian+/basketball.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian+/bump.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian+/umbrella.mp4" type="video/mp4">
            </video>
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Rendering Comparisons</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Baselines: NeRF-like <a href="https://zju3dv.github.io/enerf/" target="_blank">ENeRF</a>, image-based rendering <a href="https://ibrnet.github.io/" target="_blank">IBRNet</a>, Gaussian-Splatting-based <a href="https://donydchen.github.io/mvsplat/" target="_blank">MVSplat</a>, optimization-based <a href="https://guanjunwu.github.io/4dgs/" target="_blank">4D-GS</a></h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian+/RenderCompare.mp4" type="video/mp4">
            </video>
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Feed-forward Geometry Result</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Ablation studies on Depth Residual and Geometry Regularization</a></h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian+/Geo_Ablation.mp4" type="video/mp4">
            </video>
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>
  
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5"> Human-only data captured by ourselves and from <a href="https://dna-rendering.github.io/" target="_blank">DNA-Rendering</a></h6>
              <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="assets/GPS-Gaussian+/Real_Human.mp4" type="video/mp4">
              </video>
            <h6 style="color:#8899a5"> Human-scene data from <a href="https://neural-3d-video.github.io/" target="_blank">DyNeRF</a></h6>
              <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="assets/GPS-Gaussian+/FreeviewDyNeRF.mp4" type="video/mp4">
              </video>
            <h6 style="color:#8899a5"> Human-scene data captured by ourselves</h6>
              <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="assets/GPS-Gaussian+/FreeviewOurs.mp4" type="video/mp4">
              </video>
        </div>
      </div>
    </div>
  </section>
  <br>

    <!-- citing -->
    <div class="container">
      <div class="row ">
        <div class="col-12">
            <h3>Citation</h3>
            <hr style="margin-top:0px">
                <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
  <code>@article{zhou2024gpsplus,
    title={GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views},
    author={Zhou, Boyao and Zheng, Shunyuan and Tu, Hanzhang and Shao, Ruizhi and Liu, Boning and Zhang, Shengping and Nie, Liqiang and Liu, Yebin},
    journal={arXiv preprint arXiv:2411.11363},
    year={2024}
  }</code></pre>
            <hr>
        </div>
      </div>
    </div>
  
  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
