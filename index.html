<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Boyao Zhou</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Boyao Zhou</name>
              </p>

	      <heading>About</heading>

              <p style="text-align:left">
               I am currently working as a post-doc researcher with <a href="https://liuyebin.com/">Yebin Liu</a> in Tsinghua University for digital humans.
	      </p>
	      <p style="text-align:left">
               In 2022, I obtained a PhD degree from INRIA Rhône-Alpes & Université Grenoble Alpes (France) under the supervision of <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a> and <a href="https://morpheo.inrialpes.fr/~franco/">Jean-Sébastien Franco</a> for the research of 3D vision. During my PhD, I was working closely with HoloLens team of Microsoft Zürich & Cambridge.
              </p>
	      <p style="text-align:left">
               In 2018, I received an Engineer degree from Ecole Polytechnique (France) and a Master's degreee from Paris-Saclay University (France) in Data Sciences. Prior to that, I graduated from Tongji University (China).
	      </p>
	      <p>
	      contact: bzhou22@mail.tsinghua.edu.cn
	      </p>
	      <p style="color:red"> I am looking for the next position, starting from May 2025.</p>
            </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="img/0004.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="img/0004.jpg" class="hoverZoomLink"></a>
              </td>
          </tr>
        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	
	<!--- gps+--->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/GPSplus.mp4' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!--<a href="https://arxiv.org/pdf/2312.02155.pdf">-->
                <papertitle>GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views</papertitle>
              <!--</a>-->
              <br>
              <strong>Boyao Zhou</strong>, <a href="https://shunyuanzheng.github.io/">Shunyuan Zheng</a>, <a href="https://itoshiko.com/" target="_blank">Hanzhang Tu</a>, <a href="https://dsaurus.github.io/saurus/">Ruizhi Shao</a>, <a href="https://liuboning2.github.io/">Boning Liu</a>, <a href="https://homepage.hit.edu.cn/zhangshengping/">Shengping Zhang</a>, <a href="https://liqiangnie.github.io/">Liqiang Nie</a>, and <a href="http://liuyebin.com/">Yebin Liu</a>
              <br>
              <em>Under Review</em> 
	      /
	      <a href="https://yaourtb.github.io/GPS-Gaussian+">Project page</a>
              <br>
              <p>
                We present GPS-Gaussian+, a generalizable 3D Gaussian Splatting, for human-centered scene rendering from sparse views in a feed-forward manner.
              </p>
          </tr>
		
	<!--- siggraph2024 tele-aloha--->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/Tele-Aloha.gif' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
	      <a href="https://arxiv.org/pdf/2405.14866">
                <papertitle>Tele-Aloha: A Telepresence System with Low-budget and High-authenticity Using Sparse RGB Cameras</papertitle>
              </a>
              <br>
              Hanzhang Tu, <a href="https://dsaurus.github.io/saurus/">Ruizhi Shao</a>, Xue Dong, <a href="https://shunyuanzheng.github.io/">Shunyuan Zheng</a>, Hao Zhang, Lili Chen, Meili Wang, Wenyu Li, Siyan Ma, <a href="https://homepage.hit.edu.cn/zhangshengping/">Shengping Zhang</a>, <strong>Boyao Zhou*</strong>, and <a href="http://liuyebin.com/">Yebin Liu</a>* (Corresponding author*)
              <br>
              <em>SIGGRAPH2024 Conference Proceedings</em> 
	      /
	      <a href="http://118.178.32.38/c/Tele-Aloha/">Project page</a>
              <br>
              <p>
                We present a low-budget and high-authenticity bidirectional telepresence system, Tele-Aloha, targeting peer-to-peer communication scenarios.
              </p>
          </tr>
		
	<!--- cvpr2024 gps--->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/live.gif' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.02155.pdf">
                <papertitle>GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://shunyuanzheng.github.io/">Shunyuan Zheng</a>, <strong>Boyao Zhou</strong>, <a href="https://dsaurus.github.io/saurus/">Ruizhi Shao</a>, <a href="https://liuboning2.github.io/">Boning Liu</a>, <a href="https://homepage.hit.edu.cn/zhangshengping/">Shengping Zhang</a>, <a href="https://liqiangnie.github.io/">Liqiang Nie</a>, and <a href="http://liuyebin.com/">Yebin Liu</a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR2024)</em> 
	      /
	      <a href="https://shunyuanzheng.github.io/GPS-Gaussian">Project page</a>
              /
              <a href="https://github.com/ShunyuanZheng/GPS-Gaussian">Code</a>
              <br>
              <p>
                We propose GPS-Gaussian, a generalizable pixel-wise 3D Gaussian representation for synthesizing novel views of any unseen characters instantly without any fine-tuning or optimization.
              </p>
          </tr>

	<!--- cvpr2024 control4d--->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/control4d.png' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2305.20082">
                <papertitle>Control4D: Efficient 4D Portrait Editing with Text</papertitle>
              </a>
              <br>
              <a href="https://dsaurus.github.io/saurus/">Ruizhi Shao</a>, <a href="https://mrtornado24.github.io/">Jingxiang Sun</a>, Cheng Peng, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <strong>Boyao Zhou</strong>, <a href="https://hongwenzhang.github.io/">Hongwen Zhang</a>, and <a href="http://liuyebin.com/">Yebin Liu</a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR2024)</em> 
	      /
	      <a href="https://control4darxiv.github.io">Project page</a>
              <br>
              <p>
                We introduce Control4D, an innovative framework for editing dynamic 4D portraits using text instructions.
              </p>
          </tr>
	<!--- cvpr2024 gaussianavatar--->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/gaussianavatar.gif' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.02134.pdf">
                <papertitle>GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians</papertitle>
              </a>
              <br>
              <a href="https://huliangxiao.github.io/">Liangxiao Hu</a>, <a href="https://hongwenzhang.github.io/">Hongwen Zhang</a>, <a href="https://zhangyux15.github.io/">Yuxiang Zhang</a>, <strong>Boyao Zhou</strong>, <a href="https://liuboning2.github.io/">Boning Liu</a>, <a href="https://homepage.hit.edu.cn/zhangshengping/">Shengping Zhang</a>, and <a href="https://liqiangnie.github.io/">Liqiang Nie</a></a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR2024)</em> 
	      /
	      <a href="https://huliangxiao.github.io/GaussianAvatar">Project page</a>
              /
              <a href="https://github.com/aipixel/GaussianAvatar">Code</a>
              <br>
              <p>
                We present GaussianAvatar, an efficient approach to creating realistic human avatars with dynamic 3D appearances from a single video.
              </p>
          </tr>
		
	<!--- iccv2023 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/iccv2023_intrinsic.jpg' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2308.09519">
                <papertitle>Leveraging Intrinsic Properties for Non-Rigid Garment Alignment</papertitle>
              </a>
              <br>
              <a href="https://jsnln.github.io/">Siyou Lin</a>, <strong>Boyao Zhou</strong>, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <a href="https://hongwenzhang.github.io/">Hongwen Zhang</a>, and <a href="http://liuyebin.com/">Yebin Liu</a>
              <br>
              <em>International Conference on Computer Vision (ICCV2023)</em> 
	      /
	      <a href="iccv2023_intrinsic/index.html">Project page</a>
              /
              <a href="https://github.com/jsnln/IntrinsicGarmAlign">Code</a>
              <br>
              <p>
                We leverage intrinsic manifold properties and neural deformation fields with a coarse-to-fine two-stage method for non-rigid garment alignment.
              </p>
          </tr>

	  <!--- sig2023 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/sig23.jpg' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2304.13006.pdf">
                <papertitle>PoseVocab: Learning Joint-structured Pose Embeddings for Human Avatar Modeling</papertitle>
              </a>
              <br>
              <a href="https://lizhe00.github.io/">Zhe Li</a>, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>,  Yuxiao Liu, <strong>Boyao Zhou</strong>, and <a href="http://liuyebin.com/">Yebin Liu</a>
              <br>
              <em>SIGGRAPH2023 Conference Proceedings</em> 
	      /
	      <a href="https://lizhe00.github.io/projects/posevocab/">Project page</a>
              /
              <a href="https://github.com/lizhe00/PoseVocab">Code</a>
              <br>
              <p>
                We propose a neural avatar representation with optimal pose embeddings for learning the dynamic human appearance.
              </p>
          </tr>
		
	<!--- cvpr2023 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/cvpr2023.png' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://inria.hal.science/hal-04045719/file/CVPR2023ShapeFlow_mainpaper.pdf">
                <papertitle>Human Body Shape Completion with Implicit Shape and Flow Learning</papertitle>
              </a>
              <br>
              <strong>Boyao Zhou</strong>, Di Meng, <a href="https://morpheo.inrialpes.fr/~franco/">Jean-Sébastien Franco</a>, and <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR2023)</em> 
              <br>
              <p>
                We jointly learn human shape and flow with implicit representation for completing human shapes from partial observation.
              </p>
          </tr>

	<!--- accv2022 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/accv2022.png' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.inria.fr/hal-03806996/file/pyramidcomplete.pdf">
                <papertitle>Pyramidal Signed Distance Learning for Spatio-Temporal Human Shape Completion</papertitle>
              </a>
              <br>
              <strong>Boyao Zhou</strong>, <a href="https://morpheo.inrialpes.fr/~franco/">Jean-Sébastien Franco</a>, <a href="https://scholar.google.fr/citations?user=oJBGrfAAAAAJ&hl=en/">Martin Delagorce</a>, and <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>
              <br>
              <em>Asian Conference on Computer Vision (ACCV2022)</em> /<a href="https://gitlab.inria.fr/bzhou/PyramidSpatioTempoHumanShapeComplete.git">Code</a> 
              <br>
              <p>
                We propose to complete human shapes in a coarse-to-fine manner from both spatial and temporal directions.
              </p>
          </tr>

	<!--- 3dv2021 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/3dv2021.png' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.inria.fr/hal-03381387/file/STIF_hal.pdf">
                <papertitle>Spatio-Temporal Human Shape Completion With Implicit Function Networks</papertitle>
              </a>
              <br>
              <strong>Boyao Zhou</strong>, <a href="https://morpheo.inrialpes.fr/~franco/">Jean-Sébastien Franco</a>,  <a href="https://fbogo.github.io//">Federica Bogo</a>, and <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>
              <br>
              <em>International Conference on 3D Vision (3DV2021)</em> 
              <br>
              <p>
                We propose to learn a continuous implicit representation of human shapes from a sequence of partial observations.
              </p>
          </tr>

	<!--- accv2020 --->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='img/accv2020.png' width=180; height="auto">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.inria.fr/hal-02977388/file/accv.pdf">
                <papertitle>Reconstructing Human Body Mesh from Point Clouds by Adversarial GP Network</papertitle>
              </a>
              <br>
              <strong>Boyao Zhou</strong>, <a href="https://morpheo.inrialpes.fr/~franco/">Jean-Sébastien Franco</a>, <a href="https://fbogo.github.io//">Federica Bogo</a>, <a href="https://btekin.github.io//">Bugra Tekin</a>, and <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>
              <br>
              <em>Asian Conference on Computer Vision (ACCV2020)</em>
              <br>
              <p>
                We propose to reconstruct template-aligned human shapes with adversarial Gaussian Process Network from sparse point clouds.
              </p>
          </tr>
	</tbody></table>
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://hal.inria.fr/hal-01970660/file/birte2018.pdf">
                <papertitle>Anomaly Detection and Explanation Discovery on Event Streams</papertitle>
              </a>
              <br>
              Fei Song, <strong>Boyao Zhou</strong>, Quan Sun, Wang Sun, Shiwen Xia, and <a href="https://www.lix.polytechnique.fr/Labo/Yanlei.Diao///">Yanlei Diao</a>
              <br>
              <em>BIRTE2018</em>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>PhD thesis</strong> <a href="https://hal.inria.fr/tel-03880124/file/thesis.pdf">
                <papertitle>Inferring Dense Human Representation from Sparse or Incomplete Point Clouds</papertitle>
              </a>
          </tr>
	</tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr>				
	    Reviewers for CVPR, ECCV and ACCV.
	  </tr>
        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Page adapted from <a href="https://github.com/jonbarron/jonbarron_website">this website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
